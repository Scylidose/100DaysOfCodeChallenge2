{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "### *Learning from examples*\n",
    "\n",
    "Machine learning technique that teaches a computer to filter inputs (*observations*) through layers in order to learn how to predict and classify information.  \n",
    "\n",
    "**The outpute value is always related to the same single obervation from the input values.**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning\n",
    "\n",
    "Task of learning a function that maps an input to an output based on **example input-output pairs**.  \n",
    "It works with **labeled** training data made up of training examples.  \n",
    "Each example is a **pair** that’s made up of an input object (usually a vector) and the output value that you want (also called the supervisory signal).  \n",
    "Your algorithm supervises the training data and produces an inferred function which can be used to **map new examples**.\n",
    "\n",
    "### Classification task\n",
    "Includes :  \n",
    "- Detecting faces, identities, and facial expressions in images  \n",
    "- Identifying objects in images like stop signs, pedestrians, and lane markers  \n",
    "- Classifying text as spam   \n",
    "- Recognizing gestures in videos \n",
    "- Detecting voices and identifying sentiment in audio recordings  \n",
    "- Identifying speakers  \n",
    "- Transcribing speech-to-text  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-Supervised Learning\n",
    "\n",
    "Able to make use of both **labeled and unlabeled** data for training.  \n",
    "In semi-supervised learning, you’re often looking at a **lot of unlabeled** data and a **little bit of labeled** data.  \n",
    "\n",
    "Semi-supervised learning can be referred as **transductive** (*inferring correct labels for the given data*) or **inductive** (*inferring the correct mapping from X to Y*).  \n",
    "\n",
    "Deep Learning algorithms have to make at least one of those assumptions :  \n",
    "- Points that are close to each other probably share a label (**continuity assumption**).  \n",
    "- The data like to form clusters and the points that are clustered together probably share a label (**cluster assumption**).  \n",
    "- The data lie on a manifold of lower dimension than the input space (**manifold assumption**).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning\n",
    "\n",
    "Learning the **relationships** between elements in a data set and **classifying** the data **without the help of labels**.  \n",
    "\n",
    "These algorithms can include **clustering, anomaly detection, neural networks, and more**.  \n",
    "\n",
    "### Clustering\n",
    "Detection of **similarities or anomalies** within a data set.  \n",
    "Clustering can produce **highly accurate** search results by comparing documents, images, or sounds for similarities and anomalies.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# FeedForward Networks\n",
    "Network that contains inputs, outputs and hidden layers.  \n",
    "The signal can only travel in **one direction** (*forward*).  \n",
    "Input data passes into a layer where calculations are performed.  \n",
    "Each processing element computes based upon the **weighted sum** of its inputs.  \n",
    "The new values **become** the new input values that feed the next layer (feed-forward).  \n",
    "This continues through all the layers and **determines** the output.  \n",
    "\n",
    "\n",
    "# FeedBack Networks \n",
    "They can have signals traveling in **both directions using loops**.  \n",
    "**All possible connections** between neurons are allowed.  \n",
    "Since loops are present in this type of network, it becomes a **non-linear dynamic system** which **changes continuously** until it reaches a state of **equilibrium**.  \n",
    "\n",
    "## Artificial Neural Networks\n",
    "Each **synapses** get assigned **weights**.  \n",
    "By adjusting the weights, the ANN decides to what extent signals get passed along.  \n",
    "When you're training your network, you're deciding how the weights are adjusted.  \n",
    "\n",
    "\n",
    "We create an ANN where we have nodes for **input values** and **output values** and in between those, we have **hidden layer** (or layers) where the information travels before it hits the output.\n",
    "\n",
    "![ann](https://img-blog.csdn.net/20161212150643695?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYTgxOTgyNTI5NA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network \n",
    "***Convolves*** learned features with input data and uses 2D convolutional layers.  \n",
    "The CNN works by extracting features from images.  \n",
    "The features are **not trained**, they’re learned while the network trains on a set of images.  \n",
    "CNNs learn **feature detection** through tens or hundreds of hidden layers, with each layer **increasing the complexity** of the learned features.\n",
    "\n",
    "![cnn](https://miro.medium.com/max/1838/1*uAeANQIOQPqWZnnuH-VEyw.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network\n",
    "\n",
    "Recurrent neural networks (RNNs) are used for **processing language**.  \n",
    "RNN have built-in **feedback loops** where the output from one layer might be **fed back** into the layer preceding it.  \n",
    "Lends the network a sort of **memory**. \n",
    "\n",
    "![rnn](https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_6/recurrent.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Adversarial Networks\n",
    "In generative adversarial networks (GANs), two neural networks **fight it out**.  \n",
    "The **generator network** tries to create convincing *fake* data while the **discriminator** tries to tell the **difference** between the fake data and the real stuff.  \n",
    "With each training cycle, the generator **gets better** at creating fake data and the discriminator **gets sharper** at spotting the fakes.  \n",
    "\n",
    "GANs can be used for extremely interesting applications, including **generating images from written text**.  \n",
    "\n",
    "![gan](https://skymind.ai/images/wiki/GANs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Approximate number of neuron in each hidden layer \n",
    "![number](https://i.imgur.com/zXX8sUz.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
